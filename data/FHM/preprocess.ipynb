{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import copy\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from IPython.display import Image as IPythonImage\n",
    "from IPython.display import display\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goatbench loaded ...\n",
      "{'hateful': 750, 'non-hateful': 1250}\n",
      "{'dev': {'seen': {'hateful': 247, 'non-hateful': 253},\n",
      "         'unseen': {'hateful': 0, 'non-hateful': 140}},\n",
      " 'test': {'seen': {'hateful': 490, 'non-hateful': 510},\n",
      "          'unseen': {'hateful': 750, 'non-hateful': 1250}},\n",
      " 'train': {'seen': {'hateful': 3019, 'non-hateful': 5481},\n",
      "           'unseen': {'hateful': 0, 'non-hateful': 0}}}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_fhm(\n",
    "    splits,\n",
    "    root=\"./\", \n",
    "    version=\"v1\",\n",
    "    save_data_jsons=False, \n",
    "    include_gt_captions=False,\n",
    "):\n",
    "    # # Process Goatbench\n",
    "    gb_folder = \"../../data/GoatBench/hatefulness/\"\n",
    "    gb_save_to = \"\"\n",
    "    gb_count = 0\n",
    "    GB_items = {}\n",
    "    if os.path.exists(gb_folder):\n",
    "        gb_path = os.path.join(gb_folder, \"test.jsonl\")\n",
    "        f = open(gb_path, 'r')\n",
    "        for line in f:\n",
    "            one_data = json.loads(line)\n",
    "            if one_data[\"id\"] not in GB_items:\n",
    "                GB_items[one_data[\"id\"]] = {'label': int(one_data[\"label\"]), 'text': one_data[\"text\"]}\n",
    "        gb_save_to = \"../../data/GoatBench/data/hatefulness/\"\n",
    "        if not os.path.exists(gb_save_to):\n",
    "            os.makedirs(gb_save_to)\n",
    "        gb_statistics = {'hateful': 0, 'non-hateful': 0}\n",
    "        print(\"Goatbench loaded ...\")\n",
    "    \n",
    "    save_to = os.path.join(root, 'data')\n",
    "    if not os.path.exists(save_to):\n",
    "        os.makedirs(save_to)\n",
    "    ori_image_path = os.path.join(root, version, 'img')\n",
    "    new_image_path = os.path.join(root, version, 'Images')\n",
    "\n",
    "    all_data = {sp: {} for sp in splits}\n",
    "    data_statistics = {sp: {'seen': {'hateful': 0, 'non-hateful': 0}, 'unseen': {'hateful': 0, 'non-hateful': 0}} for sp in splits}\n",
    "    for sp in splits:\n",
    "        if sp == 'train':\n",
    "            raw_files = {'seen': os.path.join(root, version,f\"{sp}.jsonl\")}\n",
    "        else:\n",
    "            raw_files = {ssp: os.path.join(root, version, f\"{sp}_{ssp}.jsonl\") for ssp in ['seen', 'unseen']}\n",
    "            annotations = {}\n",
    "        if include_gt_captions:\n",
    "            for ssp in ['seen', 'unseen']:\n",
    "                anno_file = os.path.join(\"./caption_annotations\", f\"{sp}_{ssp}.json\")\n",
    "                if os.path.exists(anno_file):\n",
    "                    annotations[ssp] = json.load(open(anno_file)) # a dict {\"12\": {'img':, 'gt_caption':}}\n",
    "\n",
    "        for key, file in raw_files.items():\n",
    "            f = open(file, 'r')\n",
    "            for line in f:\n",
    "                one_data = json.loads(line)\n",
    "                one_data[\"is_seen\"] = 1 if key == 'seen' else 0\n",
    "                if include_gt_captions:\n",
    "                    one_data['gt_description'] = \"\"\n",
    "                    if annotations[key] and (one_data[\"id\"] in annotations[key]):\n",
    "                        one_data['gt_description'] = annotations[key][one_data[\"id\"]][\"gt_caption\"]\n",
    "                \n",
    "                # -------------------- Copy and move image -------------------- #\n",
    "                # one_data[\"img\"] = './data/FHM/' + version + '/' + one_data[\"img\"] \n",
    "                # # one_data[\"img_mask\"] = './data/FHM/' + version + '/img_mask/' + \"mask_\" + one_data[\"img\"].split(\"/\")[-1]\n",
    "\n",
    "                label_folder = str(one_data[\"label\"])\n",
    "                img = one_data.pop(\"img\")\n",
    "                img = img.split(\"/\")[-1]\n",
    "                new_split_image_path = os.path.join(new_image_path, sp, label_folder)\n",
    "                if not os.path.exists(new_split_image_path):\n",
    "                    os.makedirs(new_split_image_path)\n",
    "                new_img_path = os.path.join(new_split_image_path, img)\n",
    "                if not os.path.exists(new_img_path):\n",
    "                    ori_img_path = os.path.join(ori_image_path, img)\n",
    "                    assert os.path.exists(ori_img_path)\n",
    "                    shutil.copy(ori_img_path, new_img_path)\n",
    "                one_data['img'] = os.path.join('./data/FHM/', version, 'Images', sp, label_folder, img)\n",
    "\n",
    "                \n",
    "                if GB_items:\n",
    "                    if one_data[\"id\"] in list(GB_items.keys()):\n",
    "                        gb_count += 1\n",
    "                        one_gb = copy.deepcopy(one_data)\n",
    "                        one_gb.pop(\"label\")\n",
    "                        one_gb.pop(\"text\")\n",
    "                        one_gb[\"task\"] = \"fhm\"\n",
    "                        ori_item = GB_items[one_data[\"id\"]]\n",
    "                        GB_items[one_data[\"id\"]] = dict(**ori_item, **one_gb)\n",
    "                        lb = 'hateful' if ori_item['label'] == 1 else 'non-hateful'\n",
    "                        gb_statistics[lb] += 1\n",
    "                label = 'hateful' if one_data[\"label\"] == 1 else 'non-hateful'\n",
    "                if one_data[\"id\"] not in all_data[sp]:\n",
    "                    all_data[sp][one_data[\"id\"]] = one_data\n",
    "                    # all_data[sp].append(one_data)\n",
    "                    data_statistics[sp][key][label] += 1\n",
    "        \n",
    "        if save_data_jsons:\n",
    "            if sp != 'test':\n",
    "                json.dump([item for _, item in all_data[sp].items()], open(os.path.join(save_to, f'{sp}.json'), 'w'), indent=4)\n",
    "            else:\n",
    "                all_ffc_ids = json.load(open(\"FFC_seen.json\"))\n",
    "                ffc_ids = all_ffc_ids['GT_hateful']\n",
    "\n",
    "                new_data = {'seen': [], 'unseen': [], 'seen_ffc': []}\n",
    "                for _, item in all_data[sp].items():\n",
    "                    if item[\"is_seen\"]:\n",
    "                        new_data['seen'].append(item)\n",
    "                        if (item['id'] in ffc_ids):\n",
    "                            new_data['seen_ffc'].append(item)\n",
    "                    else:\n",
    "                        new_data['unseen'].append(item)\n",
    "                for k, v in new_data.items():\n",
    "                    json.dump(v, open(os.path.join(save_to, f'{sp}_{k}.json'), 'w'), indent=4)\n",
    "    if save_data_jsons and GB_items:\n",
    "        print(f\"#GOATBENCH Instances = {gb_count} = {len(GB_items)}\")\n",
    "        json.dump([item for _, item in GB_items.items()], open(os.path.join(gb_save_to, f'test.json'), 'w'), indent=4)\n",
    "    if GB_items:\n",
    "        print(pprint.pformat(gb_statistics))\n",
    "    \n",
    "    print(pprint.pformat(data_statistics))\n",
    "    return\n",
    "splits = ['train', 'dev', 'test']\n",
    "preprocess_fhm(splits, save_data_jsons=False, include_gt_captions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#data to be annotated in test_seen: 388\n"
     ]
    }
   ],
   "source": [
    "def fhm_gen_annotation_sheet(source_paths):\n",
    "    sep = \"fhm/\"\n",
    "    save_to = \"./caption_annotations\"\n",
    "    if not os.path.exists(save_to):\n",
    "        os.makedirs(save_to)\n",
    "    splits = list(set([src.split(sep)[1].split(\"/\")[0] for src in source_paths]))\n",
    "    splits_save_to = {sp: os.path.join(save_to, f'{sp}.json') for sp in splits}\n",
    "    #data_to_annotate = {sp: {} for sp in splits}\n",
    "    data_to_annotate = {}\n",
    "    for sp, path in splits_save_to.items():\n",
    "        if os.path.exists(path):\n",
    "            data_to_annotate[sp] = json.load(open(path))\n",
    "        else:\n",
    "            data_to_annotate[sp] = {}\n",
    "    for src in source_paths:\n",
    "        split = src.split(sep)[1].split(\"/\")[0]\n",
    "        for item in json.load(open(src)):\n",
    "            if item['id'] not in data_to_annotate[split]:\n",
    "                data_to_annotate[split][item['id']] = {\n",
    "                    'img': item['img'],\n",
    "                    'gt_caption': ''''''\n",
    "                }\n",
    "    for sp, data in data_to_annotate.items():\n",
    "        json.dump(data, open(splits_save_to[sp], 'w'), indent=4)\n",
    "        print(f\"#data to be annotated in {sp}: {len(data)}\")\n",
    "    return\n",
    "\n",
    "sources = [\n",
    "    \"/data/fengjun/projects/LLM/meme/HMC/results/fhm/test_seen/seed-42/qwen2.5-14bf/D6m_llava1.6-7bf_qwen2-vl-7bf_len-1024_GPU-2_20250307033413/round-5_Decision-v3-v0/incorrect.json\",\n",
    "    \"/data/fengjun/projects/LLM/meme/HMC/results/fhm/test_seen/seed-42/qwen2.5-14bf/D6h_llava1.6-7bf_qwen2-vl-7bf_len-1024_GPU-2_20250304221905/round-1_Decision-v3-v0/incorrect.json\",\n",
    "    \"/data/fengjun/projects/LLM/meme/HMC/results/fhm/test_seen/seed-42/qwen2.5-14bf/D6j_llava1.6-7bf_qwen2-vl-7bf_len-1024_GPU-2_20250305203152/round-1_Decision-v3-v0/incorrect.json\",\n",
    "    \"/data/fengjun/projects/LLM/meme/HMC/results/fhm/test_seen/seed-42/qwen2.5-14bf/D6h_llava1.6-7bf_qwen2-vl-7bf_len-1024_GPU-2_20250304221905/round-1_Decision-v3-v0/incorrect.json\",\n",
    "    \"/data/fengjun/projects/LLM/meme/HMC/results/fhm/test_seen/seed-42/qwen2.5-14bf/D6f_llava1.6-7bf_qwen2-vl-7bf_len-1024_GPU-2_20250304182545/round-1_Decision-v3-v0/incorrect.json\"\n",
    "]\n",
    "fhm_gen_annotation_sheet(sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
